{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "# importing grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import our models\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#importing os\n",
    "import os\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>season</th>\n",
       "      <th>home_win</th>\n",
       "      <th>home_rolling_fg</th>\n",
       "      <th>home_rolling_fga</th>\n",
       "      <th>home_rolling_fg%</th>\n",
       "      <th>home_rolling_3p</th>\n",
       "      <th>home_rolling_3pa</th>\n",
       "      <th>...</th>\n",
       "      <th>away_rolling_opponent_drb%_max</th>\n",
       "      <th>away_rolling_opponent_trb%_max</th>\n",
       "      <th>away_rolling_opponent_ast%_max</th>\n",
       "      <th>away_rolling_opponent_stl%_max</th>\n",
       "      <th>away_rolling_opponent_blk%_max</th>\n",
       "      <th>away_rolling_opponent_tov%_max</th>\n",
       "      <th>away_rolling_opponent_usg%_max</th>\n",
       "      <th>away_rolling_opponent_ortg_max</th>\n",
       "      <th>away_rolling_opponent_drtg_max</th>\n",
       "      <th>away_rolling_opponent_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>LAL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>1</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.510333</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.683333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>43.016667</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>8.016667</td>\n",
       "      <td>47.266667</td>\n",
       "      <td>33.933333</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>119.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-09</td>\n",
       "      <td>MIL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>1</td>\n",
       "      <td>45.166667</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>0.509833</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>37.966667</td>\n",
       "      <td>25.133333</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.566667</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>31.833333</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>101.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>BRK</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>0</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>90.333333</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>43.883333</td>\n",
       "      <td>25.016667</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.883333</td>\n",
       "      <td>47.533333</td>\n",
       "      <td>34.033333</td>\n",
       "      <td>169.833333</td>\n",
       "      <td>113.166667</td>\n",
       "      <td>106.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>GSW</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>1</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>44.950000</td>\n",
       "      <td>26.050000</td>\n",
       "      <td>48.866667</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>12.916667</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>32.033333</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>123.166667</td>\n",
       "      <td>115.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>WAS</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>1</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>34.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>25.966667</td>\n",
       "      <td>40.816667</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>8.533333</td>\n",
       "      <td>38.566667</td>\n",
       "      <td>38.783333</td>\n",
       "      <td>208.333333</td>\n",
       "      <td>119.833333</td>\n",
       "      <td>108.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date home_team away_team   season  home_win  home_rolling_fg  \\\n",
       "0  2021-01-08       LAL       CHI  2020-21         1        44.000000   \n",
       "1  2021-01-09       MIL       CLE  2020-21         1        45.166667   \n",
       "2  2021-01-10       BRK       OKC  2020-21         0        44.666667   \n",
       "3  2021-01-10       GSW       TOR  2020-21         1        41.333333   \n",
       "4  2021-01-11       WAS       PHO  2020-21         1        44.000000   \n",
       "\n",
       "   home_rolling_fga  home_rolling_fg%  home_rolling_3p  home_rolling_3pa  ...  \\\n",
       "0         86.000000          0.510333        12.166667         31.500000  ...   \n",
       "1         88.666667          0.509833        16.666667         39.333333  ...   \n",
       "2         90.333333          0.493333        13.166667         36.166667  ...   \n",
       "3         87.500000          0.470833        14.000000         38.166667  ...   \n",
       "4         91.833333          0.479167        12.500000         34.833333  ...   \n",
       "\n",
       "   away_rolling_opponent_drb%_max  away_rolling_opponent_trb%_max  \\\n",
       "0                       37.683333                       25.166667   \n",
       "1                       37.966667                       25.133333   \n",
       "2                       43.883333                       25.016667   \n",
       "3                       44.950000                       26.050000   \n",
       "4                       45.833333                       25.966667   \n",
       "\n",
       "   away_rolling_opponent_ast%_max  away_rolling_opponent_stl%_max  \\\n",
       "0                       43.016667                        5.083333   \n",
       "1                       48.700000                        7.500000   \n",
       "2                       60.833333                        5.333333   \n",
       "3                       48.866667                        5.050000   \n",
       "4                       40.816667                        4.550000   \n",
       "\n",
       "   away_rolling_opponent_blk%_max  away_rolling_opponent_tov%_max  \\\n",
       "0                        8.016667                       47.266667   \n",
       "1                        6.566667                       56.333333   \n",
       "2                        5.883333                       47.533333   \n",
       "3                       12.916667                       56.100000   \n",
       "4                        8.533333                       38.566667   \n",
       "\n",
       "   away_rolling_opponent_usg%_max  away_rolling_opponent_ortg_max  \\\n",
       "0                       33.933333                      193.000000   \n",
       "1                       31.833333                      176.000000   \n",
       "2                       34.033333                      169.833333   \n",
       "3                       32.033333                      187.500000   \n",
       "4                       38.783333                      208.333333   \n",
       "\n",
       "   away_rolling_opponent_drtg_max  away_rolling_opponent_Total  \n",
       "0                      121.000000                   119.333333  \n",
       "1                      109.500000                   101.333333  \n",
       "2                      113.166667                   106.500000  \n",
       "3                      123.166667                   115.166667  \n",
       "4                      119.833333                   108.166667  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our data\n",
    "data_base = pd.read_pickle('data_base.pkl')\n",
    "data_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = ['date',\n",
    " 'home_team',\n",
    " 'away_team',\n",
    " 'season',\n",
    " 'home_win' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our list of information columns. Note that these variables are all present before a game actually happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set shape: (2027, 264), target series shape: (2027,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test\n",
    "X = data_base.loc[:, ~data_base.columns.isin(info_cols)] # excluding info_cols\n",
    "y = data_base['home_win']\n",
    "\n",
    "print(f'Feature set shape: {X.shape}, target series shape: {y.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform Feature Scaling when we are dealing with Gradient Descent Based algorithms (Linear and Logistic Regression, Neural Network) and Distance-based algorithms (KNN, K-means, SVM) as these are very sensitive to the range of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data scaling and pipeline libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Creating a class that initializes the model and the parameters, and we just need to pass the scaling method for the pipeline\n",
    "\n",
    "class ModelParams:\n",
    "        \"\"\" Info:\n",
    "         This class initializes the parameters and scalers for the models, which will be used for gridsearchcv,\n",
    "         and their scaling methods.\n",
    "          Input:\n",
    "           model: the model to be used\n",
    "            scaler: Default = False, if True, the model will be scaled accordily with its respective scaler\n",
    "          Output:\n",
    "           get_pipe: returns the model pipeline and its parameters\n",
    "           model_name: returns the model name\n",
    "             \"\"\"\n",
    "                \n",
    "        #models_list = [LogisticRegression(random_state=42), LinearSVC(random_state=42), RandomForestClassifier(random_state=42), XGBClassifier(random_state=42)]     \n",
    "    \n",
    "        #creating the models  parameters dictionary\n",
    "        # Parameters of pipelines can be set using '__' separated parameter names:\n",
    "        \n",
    "        models_params = {\n",
    "            'LogisticRegression': {'logisticregression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                                      'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                        'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                          'logisticregression__max_iter': [10000]},\n",
    "            'LinearSVC': {'linearsvc__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'linearsvc__loss': ['hinge', 'squared_hinge'],\n",
    "                             'linearsvc__max_iter': [10000]},\n",
    "            'RandomForestClassifier': {'randomforestclassifier__n_estimators': [100, 200, 300, 400, 500],\n",
    "                                          'randomforestclassifier__criterion':['gini', 'entropy', 'log_loss'],\n",
    "                                         'randomforestclassifier__max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
    "                                           'randomforestclassifier__min_samples_split': [None, 2, 5, 10],\n",
    "                                             'randomforestclassifier__min_samples_leaf': [None, 1, 2, 4],\n",
    "                                         'randomforestclassifier__max_features': ['sqrt', 'log2', None],\n",
    "                                           'randomforestclassifier__min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, None],\n",
    "                                         'randomforestclassifier__max_leaf_nodes': [None, 5, 10, 15, 20, 25, 30],\n",
    "                                           'randomforestclassifier__min_impurity_decrease': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
    "            'XGBClassifier': {'xgbclassifier__n_estimators': [100, 200, 300, 400, 500], 'xgbclassifier__max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
    "                                 'xgbclassifier__learning_rate': [0.001, 0.01, 0.1, 1], 'xgbclassifier__min_child_weight': [1, 3, 5],\n",
    "                                   'xgbclassifier__gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'xgbclassifier__subsample': [None, 0.6, 0.8, 1.0],\n",
    "                                     'xgbclassifier__colsample_bytree': [None, 0.6, 0.8, 1.0], 'xgbclassifier__reg_alpha': [0, 0.001, 0.005, 0.01, 0.05, 1.5]}\n",
    "        }\n",
    "\n",
    "        #creating the models respective scalers:\n",
    "        models_scalers = {\n",
    "                'LogisticRegression': StandardScaler(),\n",
    "                'LinearSVC': StandardScaler(),\n",
    "                'RandomForestClassifier': MinMaxScaler(),\n",
    "                'XGBClassifier': MinMaxScaler()\n",
    "        }\n",
    "        \n",
    "        #creating the models respective pipelines and its parameters\n",
    "        def __init__(self, model, scaler=False):\n",
    "                \"\"\" Info:\n",
    "                 This method initializes the model and the scaling method\n",
    "                  ---------------------------------------------------------------------------------------------\n",
    "\n",
    "                   Input:\n",
    "                    model: the model to be used\n",
    "                     Scaler: boolean\n",
    "                      -------------------------------------------------------------------------------------------\n",
    "                      \n",
    "                       Output:\n",
    "                        None \"\"\"\n",
    "                \n",
    "                self.model = model\n",
    "                self.scaler = scaler\n",
    "                self.model_name = model.__class__.__name__\n",
    "\n",
    "        def get_pipe(self):\n",
    "                \"\"\" Info:\n",
    "                 This method returns the model pipeline and its parameters and the model name\n",
    "                  ---------------------------------------------------------------------------------------------\n",
    "\n",
    "                   Input:\n",
    "                    None\n",
    "                    ---------------------------------------------------------------------------------------------\n",
    "\n",
    "                     Output:\n",
    "                      model pipeline, model parameters, model name \"\"\"\n",
    "                \n",
    "                self.params = self.models_params[self.model_name]\n",
    "                if self.scaler:\n",
    "                        self.scaler = self.models_scalers[self.model_name]\n",
    "                else:\n",
    "                        self.scaler = None\n",
    "                return make_pipeline(self.scaler, self.model), self.params, self.model_name\n",
    "                \n",
    "               \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "              \n",
    "      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a class to take in the model and return the metrics of this model with the best parameters,\n",
    "# using for this the GridSearchCV function\n",
    "class ModelDevelopment:\n",
    "    \"\"\" Takes in the model, the X and y data and splits the data into train and test sets.\n",
    "    Functions:\n",
    "    - grid_search: Takes in the parameters to be tested and the scoring metric and returns the best model, best parameters and best score\n",
    "    - model_metrics: Prints the accuracy, precision, recall, f1 and auc of best model parameters found by the grid search against the test set\n",
    "    - roc_curve: Plots the ROC curve of the best model parameters found by the grid search against the test set\"\"\"\n",
    "\n",
    "    def __init__(self, model, model_name, X, y):\n",
    "        \"\"\" Info:\n",
    "            Takes in the model, the X and y data and splits the data into train and test sets.\n",
    "\n",
    "            Input:\n",
    "            model: Model to be tested\n",
    "            model_name: Name of the model to be tested\n",
    "            X: Feature set\n",
    "            y: Target series\n",
    "            scaling_method: Scaling method to be used in the pipeline\n",
    "\n",
    "            Output:\n",
    "            X_train: Feature set for the train set\n",
    "            X_test: Feature set for the test set\n",
    "            y_train: Target series for the train set\n",
    "            y_test: Target series for the test set\n",
    "            \n",
    "                    \"\"\"\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.best_model = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def grid_search(self, params, scoring): # scoring is the metric we want to optimize, mostly 'roc_auc'\n",
    "        \"\"\" Info:\n",
    "            Takes in the parameters to be tested and the scoring metric and returns the best model, best parameters and best score\n",
    "             Input:\n",
    "              params: Dictionary with the parameters to be tested\n",
    "              scoring: Metric to be optimized\n",
    "             Output:\n",
    "              best_model: Best model found by the grid search\n",
    "              best_params: Best parameters found by the grid search\n",
    "              best_score: Best score found by the grid search \"\"\"\n",
    "        \n",
    "        grid = GridSearchCV(self.model, params, cv=5, scoring=scoring, n_jobs=-1, verbose=2) #verbose = 2 so we can watch the progress in more detail\n",
    "        #trying to fit the model with the parameters\n",
    "        try:\n",
    "            grid.fit(self.X, self.y)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            pass\n",
    "        self.best_model = grid.best_estimator_\n",
    "        self.best_params = grid.best_params_\n",
    "        self.best_score = grid.best_score_\n",
    "        return self.best_model, self.best_params, self.best_score\n",
    "        \n",
    "    \n",
    "    def model_metrics(self):\n",
    "        \"\"\" Prints the accuracy, precision, recall, f1 and auc of best model parameters found by the grid search against the test set\n",
    "            For this, we use the pre split X test and y test data, which are 20% of the original data\n",
    "          \"\"\"\n",
    "        y_pred = self.best_model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred)\n",
    "        recall = recall_score(self.y_test, y_pred)\n",
    "        f1 = f1_score(self.y_test, y_pred)\n",
    "        auc = roc_auc_score(self.y_test, y_pred)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "        print('F1: ', f1)\n",
    "        print('AUC: ', auc)\n",
    "        \n",
    "    \n",
    "    def roc_curve(self):\n",
    "        \"\"\" Plots the ROC curve of the best model parameters found by the grid search against the test set\n",
    "            For this, we use the pre split X test and y test data, which are 20% of the original data\n",
    "          \"\"\"\n",
    "        y_pred_proba = self.best_model.predict_proba(self.X_test)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(self.y_test, y_pred_proba)\n",
    "        plt.plot([0,1], [0,1], 'k--')\n",
    "        plt.plot(fpr, tpr, label=self.model_name)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(self.model_name+' ROC Curve')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that uses the ModelParams class to instantiates the model, its parameters and its respective scaler. Then, it instantiates the ModelDevelopment class and \n",
    "#uses the grid_search function to find the best parameters for the model.\n",
    "def instantiate_best_model(model, X, y, scoring, scaler=True):\n",
    "        \"\"\" Info:\n",
    "                returns the model tunned with the best parameters\n",
    "            -------------------------------------------------\n",
    "             Input:\n",
    "                model: Model to be tested\n",
    "                X: Feature set\n",
    "                y: Target series\n",
    "                scoring: Metric to be optimized\n",
    "                scaler: Whether to use a scaler or not\n",
    "             ------------------------------------------------\n",
    "             Output:\n",
    "               best_model: Best model found by the grid search\n",
    "               best_params: Best parameters found by the grid search\n",
    "               best_score: Best score found by the grid search \"\"\"\n",
    "        \n",
    "        # Using the ModelParams class to instantiate the model, its parameters and its respective scaler\n",
    "        model_params = ModelParams(model, scaler)\n",
    "        pipe, params, model_name = model_params.get_pipe()\n",
    "        #checking if the model is already saved in the models folder\n",
    "        if scaler:\n",
    "                if os.path.exists('models/'+model_name+'.pkl'):\n",
    "                        pass\n",
    "        else:\n",
    "                if os.path.exists('models/'+model_name+'_unscaled.pkl'):\n",
    "                        pass       \n",
    "        # Using the ModelDevelopment class to instantiate the model\n",
    "        clf_instance = ModelDevelopment(pipe, model_name, X, y)\n",
    "        # Using the grid_search function to find the best parameters for the model\n",
    "        best_model, best_params, best_score  = clf_instance.grid_search(params, scoring) # This also fits the model instance with a variety of parameters against the dataset \n",
    "        \n",
    "        #saving best model with best parameters to pickle file:  \n",
    "        file_name = 'models/'+model_name+'.pkl' if scaler else 'models/'+model_name+'_unscaled.pkl'\n",
    "        instance_name = 'models/'+model_name+'_instance.pkl' if scaler else 'models/'+model_name+'_unscaled_instance.pkl'\n",
    "        with open(file_name, 'wb') as f:\n",
    "                pickle.dump(best_model, f)\n",
    "        with open(instance_name, 'wb') as f:\n",
    "                pickle.dump(clf_instance, f)\n",
    "\n",
    "        return best_model, best_params, best_score \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.8217766\n",
      " 0.8217766  0.82174657 0.82178154 0.8217766         nan        nan\n",
      "        nan        nan        nan 0.76686821 0.76733172        nan\n",
      " 0.77118232 0.77241441        nan        nan 0.81906825        nan\n",
      " 0.81902989 0.81536094 0.81536585 0.81542009 0.81536585 0.81536097\n",
      "        nan        nan        nan        nan        nan 0.76686821\n",
      " 0.76733172        nan 0.77118232 0.77241441        nan        nan\n",
      " 0.82064031        nan 0.8207095  0.79866077 0.79865087 0.79861153\n",
      " 0.79866075 0.79866566        nan        nan        nan        nan\n",
      "        nan 0.76686821 0.76733172        nan 0.77118232 0.77241441\n",
      "        nan        nan 0.79437956        nan 0.79441391 0.78695126\n",
      " 0.78693151 0.78691685 0.78687225 0.78690193        nan        nan\n",
      "        nan        nan        nan 0.76686821 0.76733172        nan\n",
      " 0.77118232 0.77241441        nan        nan 0.77730774        nan\n",
      " 0.77806673 0.77749455 0.77752915 0.77748465 0.77770108 0.7781153\n",
      "        nan        nan        nan        nan        nan 0.76686821\n",
      " 0.76733172        nan 0.77118232 0.77241441        nan        nan\n",
      " 0.77127137        nan 0.77303974 0.77180381 0.7718384  0.77175456\n",
      " 0.77241915 0.7733503         nan        nan        nan        nan\n",
      "        nan 0.76686821 0.76733172        nan 0.77118232 0.77241441]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_search.py:984: RuntimeWarning: invalid value encountered in cast\n",
      "  results[\"rank_%s\" % key_name] = np.asarray(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m best_models_instances \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models_list:\n\u001b[1;32m----> 6\u001b[0m     best_models_instances\u001b[39m.\u001b[39mappend(instantiate_best_model(model, X, y, \u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[19], line 21\u001b[0m, in \u001b[0;36minstantiate_best_model\u001b[1;34m(model, X, y, scoring)\u001b[0m\n\u001b[0;32m     19\u001b[0m clf_instance \u001b[39m=\u001b[39m ModelDevelopment(pipe, model_name, X, y)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Using the grid_search function to find the best parameters for the model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m best_model, best_params, best_score  \u001b[39m=\u001b[39m clf_instance\u001b[39m.\u001b[39;49mgrid_search(params, scoring) \u001b[39m# This also fits the model instance with a variety of parameters against the dataset \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#saving best model with best parameters to pickle file:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mmodel_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[18], line 51\u001b[0m, in \u001b[0;36mModelDevelopment.grid_search\u001b[1;34m(self, params, scoring)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Info:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    Takes in the parameters to be tested and the scoring metric and returns the best model, best parameters and best score\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m     Input:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m      best_params: Best parameters found by the grid search\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m      best_score: Best score found by the grid search \"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, params, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39mscoring, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m grid\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my)\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_params \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1461\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1432\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1433\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[39m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[39m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1461\u001b[0m     solver \u001b[39m=\u001b[39m _check_solver(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual)\n\u001b[0;32m   1463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, numbers\u001b[39m.\u001b[39mNumber) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1464\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPenalty term must be positive; got (C=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\nba\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:447\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    442\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLogistic Regression supports only penalties in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    443\u001b[0m         \u001b[39m%\u001b[39m (all_penalties, penalty)\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    446\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m penalty \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m supports only \u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m\u001b[39m penalties, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m penalty.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m         \u001b[39m%\u001b[39m (solver, penalty)\n\u001b[0;32m    450\u001b[0m     )\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m dual:\n\u001b[0;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m supports only dual=False, got dual=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (solver, dual)\n\u001b[0;32m    454\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "#Getting the best model for each model\n",
    "#scaled data\n",
    "models_list = [LogisticRegression(random_state=42), LinearSVC(random_state=42), RandomForestClassifier(random_state=42), XGBClassifier(random_state=42)]\n",
    "best_models_instances = []\n",
    "for model in models_list:\n",
    "    best_models_instances.append(instantiate_best_model(model, X, y, 'roc_auc'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscaled data\n",
    "\n",
    "def instantiate_best_model_unscaled(model, X, y, scoring):\n",
    "        \"\"\" Info:\n",
    "            returns the model tunned with the best parameters\n",
    "             Input:\n",
    "              model: Model to be tested\n",
    "               X: Feature set\n",
    "                y: Target series\n",
    "                 scoring: Metric to be optimized\n",
    "             Output:\n",
    "              best_model: Best model found by the grid search\n",
    "               best_params: Best parameters found by the grid search\n",
    "                best_score: Best score found by the grid search \"\"\"\n",
    "        # Using the ModelParams class to instantiate the model, its parameters and its respective scaler\n",
    "        model_params = ModelParams(model, scaler=False)\n",
    "        pipe, params, model_name = model_params.get_pipe()\n",
    "        # Using the ModelDevelopment class to instantiate the model\n",
    "        clf_instance = ModelDevelopment(pipe, model_name, X, y)\n",
    "        # Using the grid_search function to find the best parameters for the model\n",
    "        best_model, best_params, best_score  = clf_instance.grid_search(params, scoring) # This also fits the model instance with a variety of parameters against the dataset \n",
    "        #saving best model with best parameters to pickle file:\n",
    "        with open('models/'+model_name+'_unscaled.pkl', 'wb') as f:\n",
    "                pickle.dump(best_model, f)\n",
    "        #saving class instance of the best model with best parameters to pickle file:\n",
    "        with open('models/'+model_name+'_instance_unscaled.pkl', 'wb') as f:\n",
    "                pickle.dump(clf_instance, f)\n",
    "\n",
    "        return best_model, best_params, best_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the best model for each model\n",
    "#unscaled data\n",
    "models_list = [LogisticRegression(random_state=42), LinearSVC(random_state=42), RandomForestClassifier(random_state=42), XGBClassifier(random_state=42)]\n",
    "best_models_instances_unscaled = []\n",
    "for model in models_list:\n",
    "    best_models_instances_unscaled.append(instantiate_best_model_unscaled(model, X, y, 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model, with the model name, the X and y data and the scaling method\n",
    "pipe, params, model_name = ModelParams(LogisticRegression(random_state=42), scaler=True).get_pipe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "240 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.8217766\n",
      " 0.8217766  0.82174657 0.82178154 0.8217766         nan        nan\n",
      "        nan        nan        nan        nan        nan 0.81906825\n",
      "        nan 0.81902989 0.81536094 0.81536585 0.81542009 0.81536585\n",
      " 0.81536097        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.82064031        nan 0.8207095  0.79866077\n",
      " 0.79865087 0.79861153 0.79866075 0.79866566        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.79437956\n",
      "        nan 0.79441391 0.78695126 0.78693151 0.78691685 0.78687225\n",
      " 0.78690193        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.77730774        nan 0.77806673 0.77749455\n",
      " 0.77752915 0.77748465 0.77770108 0.7781153         nan        nan\n",
      "        nan        nan        nan        nan        nan 0.77127137\n",
      "        nan 0.77303974 0.77180381 0.7718384  0.77175456 0.77241915\n",
      " 0.7733503         nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#testing the grid search function \n",
    "LR = ModelDevelopment(pipe, model_name, X, y).grid_search(params, 'roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression',\n",
       "                  LogisticRegression(C=0.001, max_iter=10000, random_state=42,\n",
       "                                     solver='sag'))]),\n",
       " {'logisticregression__C': 0.001,\n",
       "  'logisticregression__max_iter': 10000,\n",
       "  'logisticregression__penalty': 'l2',\n",
       "  'logisticregression__solver': 'sag'},\n",
       " 0.8217815428688355)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7684729064039408\n",
      "Precision:  0.7727272727272727\n",
      "Recall:  0.827433628318584\n",
      "F1:  0.7991452991452991\n",
      "AUC:  0.7609390363815143\n"
     ]
    }
   ],
   "source": [
    "LR.model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR.roc_curve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the models instances, with all the propertys included with the class we created, model develpment.\n",
    "\n",
    "For this, we are going to create a function that takes in a model, the respective scaler. We are going to train either with the scaler on and off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_instances = []\n",
    "def create_models_instances(scaling=True):\n",
    "    if scaling:\n",
    "        for model in ModelParams.models_params.keys():\n",
    "            models_instances.append(ModelDevelopment(model, model, X, y, scaler))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
